{
  "paragraphs": [
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637261842_2097819726",
      "id": "paragraph_1719637261842_2097819726",
      "dateCreated": "2024-06-29T00:01:01-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:403",
      "text": "import org.apache.spark.sql.types._\n\nval schema1819 = StructType(\n        Array(\n                StructField(\"nombre_zona\", StringType, true),\n                StructField(\"nombre_subzona\", StringType, true),\n                StructField(\"nombre_canton\", StringType, true),\n                StructField(\"presunta_subinfraccion\", StringType, true),\n                StructField(\"fecha_detencion_aprehension\", DateType, true),\n                StructField(\"flagrante_boleta\", StringType, true),\n                StructField(\"sexo\", StringType, true),\n                StructField(\"edad\", IntegerType, true),\n                StructField(\"nacionalidad\", StringType, true)\n            )\n    )",
      "dateUpdated": "2024-06-29T00:13:45-0500",
      "dateFinished": "2024-06-29T00:14:17-0500",
      "dateStarted": "2024-06-29T00:13:45-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.types._\n\u001b[1m\u001b[34mschema1819\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.types.StructType\u001b[0m = StructType(StructField(nombre_zona,StringType,true),StructField(nombre_subzona,StringType,true),StructField(nombre_canton,StringType,true),StructField(presunta_subinfraccion,StringType,true),StructField(fecha_detencion_aprehension,DateType,true),StructField(flagrante_boleta,StringType,true),StructField(sexo,StringType,true),StructField(edad,IntegerType,true),StructField(nacionalidad,StringType,true))\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=0",
              "$$hashKey": "object:1682"
            },
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=1",
              "$$hashKey": "object:1683"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637294560_391300027",
      "id": "paragraph_1719637294560_391300027",
      "dateCreated": "2024-06-29T00:01:34-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:479",
      "text": "val dfData11 = spark\n    .read\n    .option(\"header\", true)\n    .option(\"delimiter\", \",\")\n    .option(\"inferSchema\", true)\n    .csv(\"/home/ikestrella/utpl/data1_1.csv\")",
      "dateUpdated": "2024-06-29T00:14:17-0500",
      "dateFinished": "2024-06-29T00:14:30-0500",
      "dateStarted": "2024-06-29T00:14:17-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData11\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [Zona: string, Subzona: string ... 7 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637299516_1716341577",
      "id": "paragraph_1719637299516_1716341577",
      "dateCreated": "2024-06-29T00:01:39-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:551",
      "text": "val dfData11R = dfData11\n    .withColumnRenamed(\"Zona\", \"nombre_zona\")\n    .withColumnRenamed(\"Subzona\", \"nombre_subzona\")\n    .withColumnRenamed(\"Cantón\", \"nombre_canton\")\n    .withColumnRenamed(\"Presunta_Subinfracción\", \"presunta_subinfraccion\")\n    .withColumnRenamed(\"Fecha de Detención\", \"fecha_detencion_aprehension\")\n    .withColumnRenamed(\"Flagrante/Boleta\", \"flagrante_boleta\")\n    .withColumnRenamed(\"Sexo\", \"sexo\")\n    .withColumnRenamed(\"Edad\", \"edad\")\n    .withColumnRenamed(\"Nacionalidad\", \"nacionalidad\")",
      "dateUpdated": "2024-06-29T00:14:30-0500",
      "dateFinished": "2024-06-29T00:14:31-0500",
      "dateStarted": "2024-06-29T00:14:30-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData11R\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 7 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637352797_919088729",
      "id": "paragraph_1719637352797_919088729",
      "dateCreated": "2024-06-29T00:02:32-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:620",
      "text": "val dfData11 = dfData11R\n    .withColumn(\"edad\", $\"edad\".cast(\"Int\"))",
      "dateUpdated": "2024-06-29T00:14:31-0500",
      "dateFinished": "2024-06-29T00:14:32-0500",
      "dateStarted": "2024-06-29T00:14:31-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData11\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 7 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637435447_29410821",
      "id": "paragraph_1719637435447_29410821",
      "dateCreated": "2024-06-29T00:03:55-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:689",
      "text": "val dfData11T = dfData11.\n    withColumn(\"presunta_flagrancia\", \n        when(upper($\"flagrante_boleta\") === \"FLAGRANTE\", \"SI\")\n        .otherwise(\"NO\")\n    )",
      "dateUpdated": "2024-06-29T00:14:32-0500",
      "dateFinished": "2024-06-29T00:14:32-0500",
      "dateStarted": "2024-06-29T00:14:32-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData11T\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 8 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637446219_230221742",
      "id": "paragraph_1719637446219_230221742",
      "dateCreated": "2024-06-29T00:04:06-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:758",
      "text": "val dfData11 = dfData11T.drop(\"flagrante_boleta\")",
      "dateUpdated": "2024-06-29T00:14:32-0500",
      "dateFinished": "2024-06-29T00:14:32-0500",
      "dateStarted": "2024-06-29T00:14:32-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData11\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 7 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=2",
              "$$hashKey": "object:1833"
            },
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=3",
              "$$hashKey": "object:1834"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637459327_697327027",
      "id": "paragraph_1719637459327_697327027",
      "dateCreated": "2024-06-29T00:04:19-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:827",
      "text": "val dfData12 = spark\n    .read\n    .option(\"header\", true)\n    .option(\"delimiter\", \",\")\n    .option(\"inferSchema\", true)\n    .csv(\"/home/ikestrella/utpl/data1_2.csv\")\n    .withColumnRenamed(\"Zona\", \"nombre_zona\")\n    .withColumnRenamed(\"Subzona\", \"nombre_subzona\")\n    .withColumnRenamed(\"Cantón\", \"nombre_canton\")\n    .withColumnRenamed(\"Presunta_Subinfracción\", \"presunta_subinfraccion\")\n    .withColumnRenamed(\"Fecha de Detención\", \"fecha_detencion_aprehension\")\n    .withColumnRenamed(\"Flagrante/Boleta\", \"flagrante_boleta\")\n    .withColumnRenamed(\"Sexo\", \"sexo\")\n    .withColumnRenamed(\"Edad\", \"edad\")\n    .withColumnRenamed(\"Nacionalidad\", \"nacionalidad\")\n    .withColumn(\"edad\", $\"edad\".cast(\"Int\"))",
      "dateUpdated": "2024-06-29T00:14:32-0500",
      "dateFinished": "2024-06-29T00:14:35-0500",
      "dateStarted": "2024-06-29T00:14:32-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData12\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 6 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637478869_484559768",
      "id": "paragraph_1719637478869_484559768",
      "dateCreated": "2024-06-29T00:04:38-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:896",
      "text": "//Borrar filas vacías (valores nulos - null)\nval dfData12Clean = dfData12\n    .na\n    .drop(\"all\")",
      "dateUpdated": "2024-06-29T00:14:35-0500",
      "dateFinished": "2024-06-29T00:14:36-0500",
      "dateStarted": "2024-06-29T00:14:35-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData12Clean\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 6 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637499531_887330857",
      "id": "paragraph_1719637499531_887330857",
      "dateCreated": "2024-06-29T00:04:59-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:965",
      "text": "val dfData12 = dfData12Clean\n    .na\n    .drop(Array(\"fecha_detencion_aprehension\", \"presunta_subinfraccion\"))",
      "dateUpdated": "2024-06-29T00:14:36-0500",
      "dateFinished": "2024-06-29T00:14:36-0500",
      "dateStarted": "2024-06-29T00:14:36-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData12\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 6 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637503628_1700050125",
      "id": "paragraph_1719637503628_1700050125",
      "dateCreated": "2024-06-29T00:05:03-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1034",
      "text": "val dfData1 =\n    dfData11.unionByName(dfData12, true)",
      "dateUpdated": "2024-06-29T00:14:36-0500",
      "dateFinished": "2024-06-29T00:14:37-0500",
      "dateStarted": "2024-06-29T00:14:36-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData1\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 7 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637516379_933194520",
      "id": "paragraph_1719637516379_933194520",
      "dateCreated": "2024-06-29T00:05:16-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1103",
      "text": "%pyspark\n\nimport pandas as pd\nimport pyspark.pandas as ps\n\npandasDF2022 = pd.read_excel('/home/ikestrella/utpl/Base_de_datos_DETENIDOS_ANIO_2016_ENERO_2024.xlsx', \n        sheet_name='2022', parse_dates=['hora_detencion_aprehension'], dtype={'nombre_zona':str, 'codigo_distrito':str, 'codigo_circuito': str, 'codigo_subcircuito': str, 'numero_detenciones':'int8'})\n        \npandasDF2023 = pd.read_excel('/home/ikestrella/utpl/Base_de_datos_DETENIDOS_ANIO_2016_ENERO_2024.xlsx', sheet_name='2023', parse_dates=['hora_detencion_aprehension'], dtype={'codigo_iccs':str, 'nombre_zona':str, 'codigo_distrito':str, 'codigo_circuito': str, 'codigo_subcircuito': str, 'codigo_provincia': str, 'numero_detenciones':'int8', 'codigo_canton': 'int16', 'codigo_parroquia':str})\n\n\npandasDF2024 = pd.read_excel('/home/ikestrella/utpl/Base_de_datos_DETENIDOS_ANIO_2016_ENERO_2024.xlsx', sheet_name='2024', parse_dates=['hora_detencion_aprehension'], dtype={'codigo_iccs':str, 'nombre_zona':str, 'codigo_distrito':str, 'codigo_circuito': str, 'codigo_subcircuito': str, 'codigo_provincia': str, 'numero_detenciones':'int8', 'codigo_canton': 'int16'})\n\n",
      "dateUpdated": "2024-06-29T00:19:28-0500",
      "dateFinished": "2024-06-29T00:15:53-0500",
      "dateStarted": "2024-06-29T00:14:37-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "/home/ikestrella/utpl/spark-3.5.1-bin-hadoop3/python/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n  warnings.warn(\n<stdin>:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n<stdin>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n<stdin>:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
          }
        ]
      }
    },
    {
      "text": "%pyspark\n\npandasDF2324 = pd.concat([pandasDF2023, pandasDF2024])\n\npandasDF2022['edad'] = pd.to_numeric(pandasDF2022['edad'], errors='coerce').astype('Int32')\npandasDF2324['edad'] = pd.to_numeric(pandasDF2324['edad'], errors='coerce').astype('Int32')\npandasDF2324['codigo_parroquia'] = pd.to_numeric(pandasDF2324['codigo_parroquia'], errors='coerce').fillna(0).astype('Int32')\n\ndataDF2022 = ps.from_pandas(pandasDF2022).to_spark()\ndataDF2324 = ps.from_pandas(pandasDF2324).to_spark()\ndata2 = dataDF2022.unionByName(dataDF2324, True)\ndata2.write.mode(\"overwrite\").parquet(\"/home/ikestrella/utpl/data2.parquet\")\n",
      "user": "anonymous",
      "dateUpdated": "2024-06-29T00:21:25-0500",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=4",
              "$$hashKey": "object:2038"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637610947_1892136060",
      "id": "paragraph_1719637610947_1892136060",
      "dateCreated": "2024-06-29T00:06:50-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1172",
      "dateFinished": "2024-06-29T00:21:53-0500",
      "dateStarted": "2024-06-29T00:21:25-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "/home/ikestrella/utpl/spark-3.5.1-bin-hadoop3/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n/home/ikestrella/utpl/spark-3.5.1-bin-hadoop3/python/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          }
        ]
      }
    },
    {
      "text": "val dfData2 = spark\n    .read\n    .parquet(\"/home/ikestrella/utpl/data2.parquet\")\n\nval dfAllData = dfData1.unionByName(dfData2, true)\n\ndfAllData\n    .write\n    .mode(\"overwrite\")\n    .parquet(\"/home/ikestrella/utpl/dataproject.parquet\")\n    ",
      "user": "anonymous",
      "dateUpdated": "2024-06-29T00:22:26-0500",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=5",
              "$$hashKey": "object:2086"
            },
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=6",
              "$$hashKey": "object:2087"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637774882_170000039",
      "id": "paragraph_1719637774882_170000039",
      "dateCreated": "2024-06-29T00:09:34-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1241",
      "dateFinished": "2024-06-29T00:22:35-0500",
      "dateStarted": "2024-06-29T00:22:26-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdfData2\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [tipo: string, edad: int ... 35 more fields]\n\u001b[1m\u001b[34mdfAllData\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 35 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=7",
              "$$hashKey": "object:2210"
            },
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=8",
              "$$hashKey": "object:2211"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719637911016_252280105",
      "id": "paragraph_1719637911016_252280105",
      "dateCreated": "2024-06-29T00:11:51-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1310",
      "text": "import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\n\nval dfData11 = spark\n    .read\n    .option(\"header\", true)\n    .option(\"delimiter\", \";\")\n    .option(\"inferSchema\", true)\n    .csv(\"/home/ikestrella/utpl/bdFinal.csv/data.csv\")\n\nval reemplazos = Map(\n  'Á' -> 'A', 'É' -> 'E', 'Í' -> 'I', 'Ó' -> 'O', 'Ú' -> 'U',\n  'á' -> 'a', 'é' -> 'e', 'í' -> 'i', 'ó' -> 'o', 'ú' -> 'u',\n  'Ñ' -> 'N', 'ñ' -> 'n'\n)\n\nval caracteresBusqueda = reemplazos.keys.mkString\nval caracteresReemplazo = reemplazos.values.mkString\n\nval dfData11Actualizado = dfData11\n  .withColumn(\"nombre_provincia\", translate(col(\"nombre_provincia\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"nombre_canton\", translate(col(\"nombre_canton\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"nombre_parroquia\", translate(col(\"nombre_parroquia\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"presunta_infraccion\", translate(col(\"presunta_infraccion\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"nombre_subzona\", translate(col(\"nombre_subzona\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"nombre_parroquia\", translate(col(\"nombre_parroquia\"), caracteresBusqueda, caracteresReemplazo))\n  .withColumn(\"nombre_distrito\", translate(col(\"nombre_distrito\"), caracteresBusqueda, caracteresReemplazo))\n",
      "dateUpdated": "2024-06-29T00:22:33-0500",
      "dateFinished": "2024-06-29T00:22:50-0500",
      "dateStarted": "2024-06-29T00:22:35-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.DataFrame\n\u001b[1m\u001b[34mdfData11\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 35 more fields]\n\u001b[1m\u001b[34mreemplazos\u001b[0m: \u001b[1m\u001b[32mscala.collection.immutable.Map[Char,Char]\u001b[0m = Map(Ó -> O, ó -> o, é -> e, É -> E, á -> a, Á -> A, í -> i, Í -> I, ñ -> n, Ñ -> N, ú -> u, Ú -> U)\n\u001b[1m\u001b[34mcaracteresBusqueda\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = ÓóéÉáÁíÍñÑúÚ\n\u001b[1m\u001b[34mcaracteresReemplazo\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = OoeEaAiInNuU\n\u001b[1m\u001b[34mdfData11Actualizado\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 35 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://10.0.2.15:4040/jobs/job?id=9",
              "$$hashKey": "object:2299"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719638005008_1103583227",
      "id": "paragraph_1719638005008_1103583227",
      "dateCreated": "2024-06-29T00:13:25-0500",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:1382",
      "text": "val data2SinglePartition = dfData11Actualizado.coalesce(1)\ndata2SinglePartition.write\n  .mode(\"overwrite\")\n  .option(\"header\", \"true\")\n  .option(\"sep\", \";\")\n  .csv(\"/home/ikestrella/utpl/bdFinal1.csv\")",
      "dateUpdated": "2024-06-29T00:23:33-0500",
      "dateFinished": "2024-06-29T00:23:53-0500",
      "dateStarted": "2024-06-29T00:23:33-0500",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdata2SinglePartition\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\u001b[0m = [nombre_zona: string, nombre_subzona: string ... 35 more fields]\n"
          }
        ]
      }
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719638558687_1620742156",
      "id": "paragraph_1719638558687_1620742156",
      "dateCreated": "2024-06-29T00:22:38-0500",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:2105"
    }
  ],
  "name": "Datos",
  "id": "2JZKS8V2P",
  "defaultInterpreterGroup": "spark",
  "version": "0.11.1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Datos"
}